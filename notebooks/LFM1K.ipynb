{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import Deduplicate, MinRating, MinItemsPerUser\n",
    "from recpack.scenarios import WeakGeneralization\n",
    "\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# helpers & metrics\n",
    "from src.helper_functions.data_formatting import *\n",
    "from src.helper_functions.metrics_accuracy import *\n",
    "from src.helper_functions.metrics_coverage import *\n",
    "from src.helper_functions.metrics_exposure import *\n",
    "\n",
    "# models\n",
    "from src.recommenders.ease import myEASE\n",
    "from src.recommenders.slim_bn import BNSLIM\n",
    "from src.recommenders.fslr import FSLR\n",
    "from src.recommenders.slim_bn_admm import BNSLIM_ADMM\n",
    "from src.recommenders.mf_fair import FairMF\n",
    "from src.recommenders.fda import FDA_bpr\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = (\n",
    "    pd.read_csv(\n",
    "        \"lastfm-1k/userid-timestamp-artid-artname-traid-traname.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 2],\n",
    "        names=[\"User_id\", \"Artist_id\"], # unique pairs\n",
    "        on_bad_lines=\"skip\",\n",
    "    )\n",
    "    .groupby([\"User_id\", \"Artist_id\"])\n",
    "    .size() # number of times a user has played songs by a particular artist\n",
    "    .reset_index(name=\"Plays\")\n",
    "    .merge(\n",
    "        pd.read_csv(\n",
    "            \"lastfm-1k/userid-profile.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            usecols=[0, 2], # targeting User_id and Age columns\n",
    "            names=[\"User_id\", \"Age\"],\n",
    "            skiprows=1,\n",
    "        ),\n",
    "        on=\"User_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .dropna(subset=[\"Age\"])\n",
    ")\n",
    "\n",
    "# filter plays dataframe based on age constraint\n",
    "plays = plays[(plays[\"Age\"] >= 10) & (plays[\"Age\"] <= 90)]\n",
    "\n",
    "plays = plays[plays[\"Plays\"] > plays.groupby(\"User_id\")[\"Plays\"].transform(\"mean\")]\n",
    "plays[\"Plays\"] = 1\n",
    "\n",
    "# set threshold for age groups\n",
    "age_threshold = 30\n",
    "plays[\"Age_Group\"] = (plays[\"Age\"] > age_threshold).astype(int)\n",
    "\n",
    "with open(\"lastfm-1k/lastfm1k_artists_mbid.pkl\", 'rb') as f: \n",
    "    artists = pickle.load(f)\n",
    "with open(\"lastfm-1k/lastfm1k_genres_filtered_final.pkl\", 'rb') as f: \n",
    "    genres = pickle.load(f)\n",
    "\n",
    "# process artists data\n",
    "artists = (\n",
    "    pd.DataFrame({\"Artist_id\": artists, \"Genres\": list(genres.values())})\n",
    "    .assign(Genres=lambda df: df[\"Genres\"].apply(lambda x: \", \".join(x)).str.split(\", \"))\n",
    "    .explode(\"Genres\")\n",
    "    .replace(\"NA\", np.nan)\n",
    "    .dropna(subset=[\"Genres\"])\n",
    ")\n",
    "\n",
    "# filter the dataframe to only include rows with these genres\n",
    "artists = artists[artists[\"Genres\"].isin([\"country\", \"folk\", \"metal\", \"indie\", \"jazz\", \"hip hop\"])]\n",
    "# merge together\n",
    "plays = pd.merge(plays, artists, on=\"Artist_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_pp = DataFramePreprocessor(\"Artist_id\", \"User_id\")\n",
    "\n",
    "# define filters\n",
    "deduplicate = Deduplicate(\"Artist_id\", \"User_id\")\n",
    "min_items_per_user_filter = MinItemsPerUser(10, \"Artist_id\", \"User_id\")\n",
    "\n",
    "# add filters to pre-processor\n",
    "plays_pp.add_filter(deduplicate)\n",
    "plays_pp.add_filter(min_items_per_user_filter)\n",
    "\n",
    "# create interaction matrix object\n",
    "im = plays_pp.process(plays)\n",
    "\n",
    "# create genre to artist id dictionary (before applying deduplication filtering)\n",
    "raw_genre_dict = plays.groupby(\"Genres\")[\"Artist_id\"].apply(lambda x: list(set(x))).to_dict()\n",
    "\n",
    "# apply filters to plays frame directly\n",
    "plays = min_items_per_user_filter.apply(deduplicate.apply(plays))\n",
    "\n",
    "# genre - inner iids dictionary\n",
    "inner_genre_dict = {\n",
    "    genre: get_inner_item_ids(plays_pp, raw_iids)\n",
    "    for genre, raw_iids in raw_genre_dict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sparsity after filtering\n",
    "sparsity = 1 - im.density\n",
    "\n",
    "# calculate user interaction and item popularity ranges\n",
    "user_interactions = im.binary_values.sum(axis=1)\n",
    "item_popularities = im.binary_values.sum(axis=0)\n",
    "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
    "\n",
    "# get the raw ids of all users involved\n",
    "raw_uids = get_raw_user_ids(plays_pp, im.active_users)\n",
    "\n",
    "# create uid - age group mapping df\n",
    "age_mapping_df = plays[plays[\"User_id\"].isin(raw_uids)][[\"User_id\", \"Age_Group\"]].drop_duplicates()\n",
    "\n",
    "# get the raw/inner ids of all users involved that are above 30 (a30)\n",
    "raw_uids_a30 = age_mapping_df.loc[age_mapping_df[\"Age_Group\"] == 1, \"User_id\"].to_numpy()\n",
    "inner_uids_a30 = get_inner_user_ids(plays_pp, raw_uids_a30)\n",
    "\n",
    "# get the raw/inner ids of all users involved that are below 30 (b30)\n",
    "raw_uids_b30 = age_mapping_df.loc[age_mapping_df[\"Age_Group\"] == 0, \"User_id\"].to_numpy()\n",
    "inner_uids_b30 = get_inner_user_ids(plays_pp, raw_uids_b30)\n",
    "\n",
    "num_interactions_a30, num_interactions_b30 = im.binary_values[inner_uids_a30].sum(), im.binary_values[inner_uids_b30].sum()\n",
    "\n",
    "# table stats\n",
    "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
    "statTable1.add_row([\"LastFM\", str(im.num_active_users), str(im.num_active_items), str(im.num_interactions), str(round(sparsity*100,2))])\n",
    "print(statTable1)\n",
    "\n",
    "statTable2 = PrettyTable([\"data set\",\"attribute\",\"|Age > 30|\",\"int(Age > 30)\",\"|Age ≤ 30|\",\"int(Age ≤ 30)\"])\n",
    "statTable2.add_row([\"LastFM\", \"age\", str(len(raw_uids_a30)), str(num_interactions_a30), str(len(raw_uids_b30)), str(num_interactions_b30)])\n",
    "print(statTable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the number of plays for each user within each genre and age group\n",
    "user_genre_age_sum = plays.groupby([\"User_id\", \"Genres\", \"Age_Group\"])[\"Plays\"].sum().reset_index()\n",
    "\n",
    "# Calculate the average number of plays per user for each genre and age group\n",
    "genre_age_avg_plays = user_genre_age_sum.groupby([\"Genres\", \"Age_Group\"])[\"Plays\"].mean().reset_index()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "genre_age_avg_plays_pivot = genre_age_avg_plays.pivot(index=\"Genres\", columns=\"Age_Group\", values=\"Plays\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "genre_age_avg_plays_pivot.plot(kind=\"bar\", figsize=(15,10))\n",
    "\n",
    "plt.title(\"Average Number of Plays per User by Genre and Age Group\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Average Number of Plays per User\")\n",
    "plt.legend([f\"Age ≤ {age_threshold}\", f\"Age > {age_threshold}\"], title=\"Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define K for Top-K\n",
    "K = 10\n",
    "\n",
    "# Define alpha, the parameter that balances the importance of NDCG and Equity in the objective function.\n",
    "# Setting alpha = 0.5 gives equal weight to both metrics, aiming to balance relevance (NDCG) and fairness (Equity).\n",
    "# Adjusting alpha allows for prioritizing one metric over the other.\n",
    "# For instance, setting alpha closer to 1.0 would prioritize NDCG (accuracy), while setting it closer to 0.0 would prioritize Equity (fairness).\n",
    "alpha = 0.2\n",
    "\n",
    "# define seed; seeds tested (1452, 1994, 42, 7, 13800)\n",
    "SEED = 7\n",
    "\n",
    "# define scenario\n",
    "# Note: Due to the nature of the utilized algorithms (User-User neighborhood methods), \n",
    "# only scenarios that include the 'validation in' set in the 'validation training' set, \n",
    "# and the 'test in' set in the 'full training' set, are applicable.\n",
    "scenario = WeakGeneralization(validation=True, seed=SEED)\n",
    "scenario.split(im)\n",
    "\n",
    "# define time threshold\n",
    "SECONDS = 24*3600\n",
    "\n",
    "# define number of evaluations\n",
    "EVALUATIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_objective(model, fit_args={}):\n",
    "    model.fit(scenario.validation_training_data.binary_values, **fit_args)\n",
    "\n",
    "    # generate predictions and mask training interactions\n",
    "    predictions = model.predict(scenario.validation_training_data.binary_values).toarray()\n",
    "    predictions[scenario.validation_training_data.binary_values.nonzero()] = -np.inf\n",
    "\n",
    "    ndcg, _ = tndcg_at_n(predictions, scenario.validation_data_out.binary_values, K)\n",
    "\n",
    "    return 1-ndcg\n",
    "\n",
    "def combined_objective(model, fit_args={}):\n",
    "    model.fit(scenario.validation_training_data.binary_values, **fit_args)\n",
    "\n",
    "    if \"users_features\" in fit_args: #fda\n",
    "        predictions = model.model_.predict().toarray()\n",
    "    else:\n",
    "        predictions = model.predict(scenario.validation_training_data.binary_values).toarray()\n",
    "    predictions[scenario.validation_training_data.binary_values.nonzero()] = -np.inf\n",
    "\n",
    "    ndcg, _ = tndcg_at_n(predictions, scenario.validation_data_out.binary_values, K)\n",
    "    equity, _, _ = c_equity_at_n(predictions[inner_uids_a30, :], predictions[inner_uids_b30, :], inner_genre_dict, K)\n",
    "\n",
    "    return alpha * (1-ndcg) + (1 - alpha) * equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fairmf\n",
    "sst_field = torch.zeros((im.num_active_users, im.num_active_items), dtype=torch.bool)\n",
    "sst_field[inner_uids_a30, :] = True\n",
    "\n",
    "# for fda\n",
    "users_features = np.zeros(im.num_active_users); users_features[inner_uids_b30] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize ease\n",
    "optimisation_results_ease = fmin(\n",
    "    fn=lambda param: accuracy_objective(myEASE(l2=param[\"l2\"], method=\"user\")),\n",
    "    space={\"l2\": hp.loguniform(\"l2\", np.log(1e0), np.log(1e4))},\n",
    "    algo=tpe.suggest,\n",
    "    timeout = SECONDS,\n",
    "    max_evals = EVALUATIONS,\n",
    ")\n",
    "\n",
    "# optimize bnslim\n",
    "optimisation_results_bnslim = fmin(\n",
    "    fn=lambda param: combined_objective(BNSLIM(knn=100, l1=param[\"l1\"], l2=param[\"l2\"], l3=param[\"l3\"], method=\"user\", seed=SEED), {\"inner_ids_npr\": inner_uids_b30}),\n",
    "    space={\"l1\": hp.loguniform(\"l1\", np.log(1e-3), np.log(7)),\n",
    "           \"l2\": hp.loguniform(\"l2\", np.log(1e-3), np.log(7)),\n",
    "           \"l3\": hp.loguniform(\"l3\", np.log(1e1), np.log(1e4))\n",
    "           }, \n",
    "    algo=tpe.suggest,\n",
    "    timeout=SECONDS,\n",
    "    max_evals=EVALUATIONS\n",
    ")\n",
    "\n",
    "# optimize fslr\n",
    "optimisation_results_fslr = fmin(\n",
    "    fn=lambda param: combined_objective(FSLR(l1=param[\"l1\"], l2=param[\"l2\"], method=\"user\"), {\"inner_ids_pr\": inner_uids_a30, \"inner_ids_npr\": inner_uids_b30}),\n",
    "    space={\"l1\": hp.loguniform(\"l1\", np.log(1e-3), np.log(1e1)),\n",
    "           \"l2\": hp.loguniform(\"l2\", np.log(1e0), np.log(1e4))},\n",
    "    algo=tpe.suggest,\n",
    "    timeout=SECONDS,\n",
    "    max_evals=EVALUATIONS\n",
    ")\n",
    "\n",
    "# optimize bnslim admm\n",
    "optimisation_results_bnslim_admm = fmin(\n",
    "    fn=lambda param: combined_objective(BNSLIM_ADMM(l1=param[\"l1\"], l2=param[\"l2\"], l3=param[\"l3\"], method=\"user\"), {\"inner_ids_npr\": inner_uids_b30}),\n",
    "    space={\"l1\": hp.loguniform(\"l1\", np.log(1e-3), np.log(50)),\n",
    "           \"l2\": hp.loguniform(\"l2\", np.log(1e0), np.log(1e4)),\n",
    "           \"l3\": hp.loguniform(\"l3\", np.log(1e-3), np.log(1e3))},\n",
    "    algo=tpe.suggest,\n",
    "    timeout = SECONDS,\n",
    "    max_evals = EVALUATIONS,\n",
    ")\n",
    "\n",
    "# optimize FairMF\n",
    "factor_choices = [32, 64, 128]\n",
    "optimisation_results_fairmf = fmin(\n",
    "    fn=lambda param: combined_objective(FairMF(batch_size=im.num_active_users, learning_rate=param[\"learning_rate\"], l2=param[\"l2\"], num_factors=param[\"num_factors\"], seed=SEED), {\"sst_field\": sst_field}),\n",
    "    space={\"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-6), np.log(1e0)),\n",
    "           \"l2\": hp.loguniform(\"l2\", np.log(1e-6), np.log(1e-1)),\n",
    "           \"num_factors\": hp.choice(\"num_factors\", factor_choices)\n",
    "           },\n",
    "    algo=tpe.suggest,\n",
    "    timeout=SECONDS,\n",
    "    max_evals=EVALUATIONS\n",
    ")\n",
    "\n",
    "optimisation_results_fairmf[\"num_factors\"] = factor_choices[optimisation_results_fairmf[\"num_factors\"]]\n",
    "\n",
    "# optimize FDA\n",
    "# define the parameter choices\n",
    "num_ng_choices = [5, 7, 9, 10]\n",
    "ratio_choices = [0.1, 0.3, 0.5, 0.7]\n",
    "all_combinations = itertools.product(num_ng_choices, ratio_choices)\n",
    "\n",
    "best_params = None\n",
    "best_score = float(\"inf\")\n",
    "\n",
    "for num_ng, noise_ratio in all_combinations:\n",
    "    score = combined_objective(\n",
    "        FDA_bpr(num_ng=num_ng, noise_ratio=noise_ratio, seed=SEED), \n",
    "        {\"users_features\": users_features}\n",
    "    )\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = {\"num_ng\": num_ng, \"noise_ratio\": noise_ratio}\n",
    "\n",
    "opt_params = {}\n",
    "opt_params.update({\n",
    "    \"ease\": optimisation_results_ease,\n",
    "    \"bnslim\": optimisation_results_bnslim,\n",
    "    \"fslr\": optimisation_results_fslr,\n",
    "    \"bnslim_admm\": optimisation_results_bnslim_admm,\n",
    "    \"fairmf\": optimisation_results_fairmf,\n",
    "    \"fda\": best_params\n",
    "})\n",
    "\n",
    "folder = f\"lastfm-1k/{SEED}\"; os.makedirs(folder, exist_ok=True)\n",
    "with open(f\"{folder}/opt_params.json\", \"w\") as f: json.dump(opt_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"lastfm-1k/{SEED}/opt_params.json\", \"r\") as f: opt_params = json.load(f)\n",
    "\n",
    "def initialize_models(opt_params):\n",
    "    return {\n",
    "        \"ease\": myEASE(l2=opt_params[\"ease\"][\"l2\"], method=\"user\"),\n",
    "        \"bnslim\": BNSLIM(knn=100, l1=opt_params[\"bnslim\"][\"l1\"], l2=opt_params[\"bnslim\"][\"l2\"], l3=opt_params[\"bnslim\"][\"l3\"], maxIter=50, method=\"user\", seed=SEED),\n",
    "        \"fslr\": FSLR(l1=opt_params[\"fslr\"][\"l1\"], l2=opt_params[\"fslr\"][\"l2\"], method=\"user\"),\n",
    "        \"bnslim_admm\": BNSLIM_ADMM(l1=opt_params[\"bnslim_admm\"][\"l1\"], l2=opt_params[\"bnslim_admm\"][\"l2\"], l3=opt_params[\"bnslim_admm\"][\"l3\"], method=\"user\"),\n",
    "        \"fairmf\": FairMF(batch_size=im.num_active_users, l2=opt_params[\"fairmf\"][\"l2\"], learning_rate=opt_params[\"fairmf\"][\"learning_rate\"], num_factors=opt_params[\"fairmf\"][\"num_factors\"], seed=SEED),\n",
    "        \"fda\": FDA_bpr(\n",
    "            noise_ratio=opt_params[\"fda\"][\"noise_ratio\"], \n",
    "            num_ng=opt_params[\"fda\"][\"num_ng\"],\n",
    "            seed=SEED\n",
    "        )\n",
    "    }\n",
    "\n",
    "# initialize models\n",
    "models = initialize_models(opt_params)\n",
    "\n",
    "# define the models, list sizes, and metrics\n",
    "list_sizes = [10, 20, 50, 100]\n",
    "metrics = [\"ndcg\", \"recall\", \"c-equity\", \"u-parity\"]\n",
    "\n",
    "# initialize a dictionary to store results with mean and standard deviation\n",
    "results = {\n",
    "    \"iters_num\": {model: 0 for model in [\"bnslim\", \"fslr\", \"bnslim_admm\", \"fairmf\"]},\n",
    "    \"fit_time\": {model: 0 for model in models.keys()},\n",
    "    **{metric: {model: {size: {\"mean\": 0, \"std\": 0} for size in list_sizes} for model in models.keys()} for metric in metrics}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    \n",
    "    print(f\"Training model {model_name}...\")\n",
    "\n",
    "    params = {}\n",
    "    if model_name == \"fslr\":\n",
    "        params = {\"inner_ids_pr\": inner_uids_a30, \"inner_ids_npr\": inner_uids_b30}\n",
    "    elif model_name in [\"bnslim\", \"bnslim_admm\"]:\n",
    "        params = {\"inner_ids_npr\": inner_uids_b30}\n",
    "    elif model_name == \"fairmf\":\n",
    "        params = {\"sst_field\": sst_field}\n",
    "    elif model_name == \"fda\":\n",
    "        params = {\"users_features\": users_features}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(scenario.full_training_data.binary_values, **params)\n",
    "    results[\"fit_time\"][model_name] = time.time() - start_time\n",
    "\n",
    "    if model_name in results[\"iters_num\"]:\n",
    "        if model_name == \"fairmf\":\n",
    "            results[\"iters_num\"][model_name] = model.epochs\n",
    "        else:\n",
    "            results[\"iters_num\"][model_name] = model.iters\n",
    "\n",
    "    # generate predictions and mask training interactions\n",
    "    if model_name == \"fda\":\n",
    "        y_pred = model.model_.predict()\n",
    "    else:\n",
    "        y_pred = model.predict(scenario.full_training_data.binary_values)\n",
    "    predictions = y_pred.toarray()\n",
    "    predictions[scenario.full_training_data.binary_values.nonzero()] = -np.inf\n",
    "\n",
    "    # compute evaluation metrics for different values of K\n",
    "    for K in list_sizes:\n",
    "        # accuracy metrics\n",
    "        results[\"ndcg\"][model_name][K][\"mean\"], results[\"ndcg\"][model_name][K][\"std\"] = tndcg_at_n(predictions, scenario.test_data_out.binary_values, K)\n",
    "        results[\"recall\"][model_name][K][\"mean\"], results[\"recall\"][model_name][K][\"std\"] = recall_at_n(predictions, scenario.test_data_out.binary_values, K)\n",
    "\n",
    "        # fairness metrics\n",
    "        results[\"c-equity\"][model_name][K][\"mean\"], results[\"c-equity\"][model_name][K][\"std\"], _ = c_equity_at_n(predictions[inner_uids_a30, :], predictions[inner_uids_b30, :], inner_genre_dict, K)\n",
    "\n",
    "        protected = np.ones(im.num_active_users); protected[inner_uids_b30] = 0\n",
    "        results[\"u-parity\"][model_name][K][\"mean\"], results[\"u-parity\"][model_name][K][\"std\"] = u_parity_at_n(predictions, protected, inner_genre_dict, K)\n",
    "\n",
    "    # # save model\n",
    "    # pickle.dump(model, open(f\"lastfm-1k/{SEED}/{model_name}.pkl\", \"wb\"))\n",
    "\n",
    "# save results\n",
    "with open(f\"lastfm-1k/{SEED}/results.json\", \"w\") as f: json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
